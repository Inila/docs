# 索引原理

+ 索引首先会写入到索引的 buffer 缓存和 translog 日志文件中, 这个期间不能被客户端索引。
+ 每隔1秒钟, buffer 缓存中的数据会被写入到新的 segment 缓存文件 file 中, 同时写入系统的缓存os caching 中,并打开索引,外部客户端可以进行索引查询,这一点说明 Elasticsearch 并不是所谓的实时索引,其中有一秒的延迟;
+ 写入 segment file 后清空 buffer 缓存数据;
+ 重复上面3个步骤, 新的segment不断增加,buffer不断清空,而transLog中的数据不断追加;
+ 当transLog长度达到一定程度的时候,或者到达一定时间的时候,发生commit操作
+ 发生commit操作的时候,所有的segment文件会被fsync强行刷到磁盘上,这个过程就是flush,默认是30分钟flush一次,或者translog过大的时候,也会触发flush
+ 现有的 translog 被清空,创建一个新的translog

# 数据恢复原理

在索引写入的过程中,只要segment缓存文件没有刷新到磁盘上,当elasticsearch集群出现宕机后,留在缓存中的数据都会丢失掉。
当出现上面数据丢失的现象后,怎么处理呢? Elasticsearch有一套容错恢复规则,当数据出现丢失后,会根据translog记录点重新生产segment缓存文件。

每一秒就是刷新Buffer,生成一个segment文件,导致文件过多,默认后台会执行segment merge操作,在merge的时候被标记为deleted的document会被彻底物理删除