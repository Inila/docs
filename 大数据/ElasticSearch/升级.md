# 集群升级

## 滚动升级(rolling upgrade)

滚动升级是在不中断服务情况下,一次升级集群中的一台机器。除了滚动升级阶段,不能在ES集群中运行多个版本的ES,因为升级的节点的Shard不能被复制到老版本节点。

滚动升级步骤

1. 关闭 shard allocation

    当关闭一个节点时, allocation 进程会等待一分钟, 然后将该节点上的shard复制到集群的其他节点,这样会引起很多无用I/O。可以在关闭节点前关闭shard分配功能,从而避免改问题。

    注意: 由于是滚动升级,不需要事先关闭所有 node, 所以应该使用 transient 而非 persistent

    ```json
    PUT _cluster/settings
    {
        "transient": {
            "cluster.routing.allocation.enable": "none"
        }
    }
    ```

2. Stop non-essential indexing and perform a synced flush.

    执行 synced flush后,会清空内存缓存和 translog 文件,同时对 segment 添加特殊标记,可以后续 shard recovery 阶段就无需 replay translog, 从而大大加快 recovery 速度。如果 index 还在写数据, sync flush 有可能失败,可以多执行几次

    ```
    POST _flush/synced
    ```

3. Shut down a single node

    ```bash
    sudo systemctl stop elasticsearch.service 或 kill $(cat pid)
    ```

    关闭结果后, ES会把其他节点上改节点 primary shard 的副本 提升为 primart shard, 这样可以保证写数据的完整性。
    当节点启动后, 会执行本地 Shard Recovery
    可以使用 GET /_cat/shards API 查看该节点上的shard分布情况,当关闭shard分配并且关闭该节点后,这些shard处于 UNASSIGN 状态,集群状态为 yellow

4. Upgrade the node you shut down

    解压新版 ES 的 tar包到新的目录,将老版本的 conf 目录下的文件复制到新 conf 目录,然后修改环境变量 ES_PATH_CONF 指向新 conf 目录。

    ```bash
    $ ./bin/elasticsearch -d
    ```

5. Upgrade any plugins.

    Use the elasticsearch-plugin script to install the upgraded version of each installed Elasticsearch plugin. **All plugins** must be upgraded when you upgrade a node.

6. Reenable shard allocation

    确保节点加入集群后，需要再开启 shard 分配，从而开始使用该节点。
    
    ```json
    PUT _cluster/settings
    {
        "transient": {
            "cluster.routing.allocation.enable": "all"
        }
    }
    ```

7. Wait for the node to recover.

    Before upgrading the next node, wait for the cluster to finish shard allocation. You can check progress by submitting a _cat/health request:

   
    GET _cat/health

    Wait for the status column to switch from yellow to green. Once the node is green, all primary and replica shards have been allocated.

    查看 index shard 的恢复情况：

    GET .watcher-history-7-2018.02.04/_recovery&active_only=true
    GET _recovery?human&detailed=true&active_only=true
    GET _cat/recovery/.watcher-history-7-2018.02.04?v&active_only=true
    GET /_cluster/health/khost-metrics-2018.02.10-000006?level=shards

    必须等待集群状态为绿色后才能操作下一个节点，否则同时关闭多个节点时，有可能造成 index 数据丢失(例如 1 副本的 index，如果恰好两个shard位于这两个关闭的节点上，那么在升级期间，数据索引就会中断，从而引起数据丢失)。

## 完整重启集群升级

完整重启集群升级需要**关闭所有**节点,升级他们,然后再启动各节点     

1. 重启集群前, 需要关闭 shard 分配, flush sync 所有索引。

    ```json
    PUT _cluster/settings
    {
        "persistent": {
            "cluster.routing.allocation.enable": "none"
    }

    注意：由于机器所有的 Node 都会先关闭，所以需要 persistent 类型的设置，这样重启时任保留设置的值；

    POST _flush/synced
    ```

2. 关闭所有节点的ES进程

3. 启动升级后的节点

    + 如果有专用 master 节点, 则需要先重启他们, 等待他们形成一个集群,并选举产生master,然后才启动各data节点。在此过程中,可以查看 master 节点日志来了解进度。
    + 选举产生 master 后, 可以使用 _cat/health、_cat/nodes API 来查看 data 节点的加入情况。
    + 节点加入后，它开始恢复本地的 primary shards，这时 _cat/health 为 red，因为 index 的所有 primary shard 没有恢复。节点恢复完本地的 shards 后，集群状态为 yellow，表明所有所有 primary shards 恢复完毕，但是有的 副本shards 并没有分配，这是预期的，因为当前 shard allocation 是禁止的。可以使用 GET _cat/shards 查看 node 上包含的 shard 和它的状态。
    + 等待所有 node 加入集群，且集群状态为 yellow，然后开启 shards 分配：

    ```json
    PUT _cluster/settings
    {
        "transient": {
            "cluster.routing.allocation.enable": "all"
        }
    }
    ```